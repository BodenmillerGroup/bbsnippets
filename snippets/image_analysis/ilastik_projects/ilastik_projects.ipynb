{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples how to extract information from ilastik projects\n",
    "\n",
    "This shows how to:\n",
    "- Export a csv that can be loaded as metata csv in cellprofiler to reproduce the 'random' cropping\n",
    "- How to dump the labels used for training\n",
    "\n",
    "\n",
    "Further useful scripts how to use ilastik from the command line, e.g. how to train it with pre-define labels, can be found here: https://github.com/ilastik/ilastik/tree/master/bin\n",
    "\n",
    "By\n",
    "vito.zanotelli@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    fn_ilastik = './exampledata/example_training.ilp'\n",
    "    fn_crop_list ='~/tmp/crop_metadata.csv' # This can be used within cellprofiler to reproduce the croping identically to the training data\n",
    "    fol_out_labels = pathlib.Path('/home/vitoz/tmp')\n",
    "C=config\n",
    "\n",
    "class variables:\n",
    "    re_crop = re.compile('(?P<basename>.*)(_s(P<scale>[0-9]+))?_x(?P<x>[0-9]+)_y(?P<y>[0-9]+)_w(?P<w>[0-9]+)_h(?P<h>[0-9]+).*')\n",
    "    COL_FN = 'filename_training'\n",
    "    SUFFIX_LABEL = '_label.npy'\n",
    "V=variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to dump a `hdf5` content nicely formated from:\n",
    "https://stackoverflow.com/a/53340677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descend_obj(obj,sep='\\t'):\n",
    "    \"\"\"\n",
    "    Iterate through groups in a HDF5 file and prints the groups and datasets names and datasets attributes\n",
    "    \"\"\"\n",
    "    if type(obj) in [h5py._hl.group.Group,h5py._hl.files.File]:\n",
    "        for key in obj.keys():\n",
    "            print(sep,'-',key,':',obj[key])\n",
    "            descend_obj(obj[key],sep=sep+'\\t')\n",
    "    elif type(obj)==h5py._hl.dataset.Dataset:\n",
    "        for key in obj.attrs.keys():\n",
    "            print(sep+'\\t','-',key,':',obj.attrs[key])\n",
    "\n",
    "def h5dump(path,group='/'):\n",
    "    \"\"\"\n",
    "    print HDF5 file metadata\n",
    "\n",
    "    group: you can give a specific group, defaults to the root group\n",
    "    \"\"\"\n",
    "    with h5py.File(path,'r') as f:\n",
    "         descend_obj(f[group])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "h5dump(C.fn_ilastik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump a metadata csv to reproduce the random crops\n",
    "\n",
    "Make a metadata file from the ilasik project filenames, that can be used to reproduce the crops by using this csv as metadta file.\n",
    "This file can be loaded in cellprofiler as metadata. The `crop bb` module from ImcPluginsCP (https://github.com/BodenmillerGroup/ImcPluginsCP) can use metadata as parameters to specify were to crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(C.fn_ilastik, 'r') as f:\n",
    "    lanes = f['Input Data']['infos'].values()\n",
    "    fns_training = [lane['Raw Data/nickname'][()].decode('UTF-8') for lane in lanes ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_names(x, re_comp):\n",
    "    c = re_comp\n",
    "    m = c.match(x)\n",
    "    g = m.groups() \n",
    "    return pd.Series({l: g[i-1] for l, i in c.groupindex.items()}, name=x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_training = pd.DataFrame({V.COL_FN: fns_training})\n",
    "dat_training = dat_training.join(dat_training[V.COL_FN].apply(split_names, re_comp=V.re_crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename_training</th>\n",
       "      <th>basename</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p1_r0_a0_ac_ila...</td>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p1_r0_a0_ac_ila...</td>\n",
       "      <td>27</td>\n",
       "      <td>482</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p1_r1_a1_ac_ila...</td>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p1_r1_a1_ac_ila...</td>\n",
       "      <td>190</td>\n",
       "      <td>1059</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p2_r2_a2_ac_ila...</td>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p2_r2_a2_ac_ila...</td>\n",
       "      <td>101</td>\n",
       "      <td>240</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p2_r3_a3_ac_ila...</td>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p2_r3_a3_ac_ila...</td>\n",
       "      <td>373</td>\n",
       "      <td>915</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p3_r6_a6_ac_ila...</td>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p3_r6_a6_ac_ila...</td>\n",
       "      <td>198</td>\n",
       "      <td>1037</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p3_r7_a7_ac_ila...</td>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p3_r7_a7_ac_ila...</td>\n",
       "      <td>848</td>\n",
       "      <td>742</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p4_r4_a4_ac_ila...</td>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p4_r4_a4_ac_ila...</td>\n",
       "      <td>394</td>\n",
       "      <td>52</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p4_r5_a5_ac_ila...</td>\n",
       "      <td>20170906_FluidigmONfinal_SE_s0_p4_r5_a5_ac_ila...</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename_training  \\\n",
       "0  20170906_FluidigmONfinal_SE_s0_p1_r0_a0_ac_ila...   \n",
       "1  20170906_FluidigmONfinal_SE_s0_p1_r1_a1_ac_ila...   \n",
       "2  20170906_FluidigmONfinal_SE_s0_p2_r2_a2_ac_ila...   \n",
       "3  20170906_FluidigmONfinal_SE_s0_p2_r3_a3_ac_ila...   \n",
       "4  20170906_FluidigmONfinal_SE_s0_p3_r6_a6_ac_ila...   \n",
       "5  20170906_FluidigmONfinal_SE_s0_p3_r7_a7_ac_ila...   \n",
       "6  20170906_FluidigmONfinal_SE_s0_p4_r4_a4_ac_ila...   \n",
       "7  20170906_FluidigmONfinal_SE_s0_p4_r5_a5_ac_ila...   \n",
       "\n",
       "                                            basename    x     y    w    h  \n",
       "0  20170906_FluidigmONfinal_SE_s0_p1_r0_a0_ac_ila...   27   482  500  500  \n",
       "1  20170906_FluidigmONfinal_SE_s0_p1_r1_a1_ac_ila...  190  1059  500  500  \n",
       "2  20170906_FluidigmONfinal_SE_s0_p2_r2_a2_ac_ila...  101   240  500  500  \n",
       "3  20170906_FluidigmONfinal_SE_s0_p2_r3_a3_ac_ila...  373   915  500  500  \n",
       "4  20170906_FluidigmONfinal_SE_s0_p3_r6_a6_ac_ila...  198  1037  500  500  \n",
       "5  20170906_FluidigmONfinal_SE_s0_p3_r7_a7_ac_ila...  848   742  500  500  \n",
       "6  20170906_FluidigmONfinal_SE_s0_p4_r4_a4_ac_ila...  394    52  500  500  \n",
       "7  20170906_FluidigmONfinal_SE_s0_p4_r5_a5_ac_ila...  860     0  500  500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_training.to_csv(C.fn_crop_list, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract ilastik training labels\n",
    "\n",
    "These labels will be saved in the label output folder as a `.npy` array.\n",
    "\n",
    "This is usefull e.g. to combine classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170906_FluidigmONfinal_SE_s0_p1_r0_a0_ac_ilastik_s2_x27_y482_w500_h500\n",
      "20170906_FluidigmONfinal_SE_s0_p1_r0_a0_ac_ilastik_s2_x27_y482_w500_h500\n",
      "20170906_FluidigmONfinal_SE_s0_p1_r1_a1_ac_ilastik_s2_x190_y1059_w500_h500\n",
      "20170906_FluidigmONfinal_SE_s0_p2_r2_a2_ac_ilastik_s2_x101_y240_w500_h500\n",
      "20170906_FluidigmONfinal_SE_s0_p2_r2_a2_ac_ilastik_s2_x101_y240_w500_h500\n",
      "20170906_FluidigmONfinal_SE_s0_p2_r2_a2_ac_ilastik_s2_x101_y240_w500_h500\n",
      "20170906_FluidigmONfinal_SE_s0_p2_r2_a2_ac_ilastik_s2_x101_y240_w500_h500\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(C.fn_ilastik, 'r') as f:\n",
    "    labels = f['/PixelClassification/LabelSets']\n",
    "    lanes = f['Input Data']['infos']\n",
    "    for label, lane in zip(labels.values(),lanes.values()):\n",
    "        name = lane['Raw Data/nickname'][()].decode('UTF-8')\n",
    "        for val in label.values():\n",
    "            print(name)\n",
    "            np.save(C.fol_out_labels / (name+V.SUFFIX_LABEL), val[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: null\n",
      "channels:\n",
      "  - r\n",
      "  - bioconda\n",
      "  - pyviz\n",
      "  - conda-forge\n",
      "  - defaults\n",
      "dependencies:\n",
      "  - _libgcc_mutex=0.1=conda_forge\n",
      "  - _openmp_mutex=4.5=1_llvm\n",
      "  - backcall=0.1.0=py_0\n",
      "  - blas=2.16=openblas\n",
      "  - ca-certificates=2019.11.28=hecc5488_0\n",
      "  - certifi=2019.11.28=py37hc8dfbb8_1\n",
      "  - decorator=4.4.2=py_0\n",
      "  - entrypoints=0.3=py37hc8dfbb8_1001\n",
      "  - h5py=2.10.0=nompi_py37h513d04c_102\n",
      "  - hdf5=1.10.5=nompi_h3c11f04_1104\n",
      "  - ipykernel=5.2.0=py37h43977f1_0\n",
      "  - ipython=7.13.0=py37hc8dfbb8_2\n",
      "  - ipython_genutils=0.2.0=py_1\n",
      "  - jedi=0.16.0=py37hc8dfbb8_1\n",
      "  - jupyter_client=6.1.0=py_0\n",
      "  - jupyter_core=4.6.3=py37hc8dfbb8_1\n",
      "  - ld_impl_linux-64=2.34=h53a641e_0\n",
      "  - libblas=3.8.0=16_openblas\n",
      "  - libcblas=3.8.0=16_openblas\n",
      "  - libffi=3.2.1=he1b5a44_1007\n",
      "  - libgcc-ng=9.2.0=h24d8f2e_2\n",
      "  - libgfortran-ng=7.3.0=hdf63c60_5\n",
      "  - liblapack=3.8.0=16_openblas\n",
      "  - liblapacke=3.8.0=16_openblas\n",
      "  - libopenblas=0.3.9=h5ec1e0e_0\n",
      "  - libsodium=1.0.17=h516909a_0\n",
      "  - libstdcxx-ng=9.2.0=hdf63c60_2\n",
      "  - llvm-openmp=9.0.1=hc9558a2_2\n",
      "  - ncurses=6.1=hf484d3e_1002\n",
      "  - numpy=1.17.0=py37h99e49ec_0\n",
      "  - numpy-base=1.17.0=py37h2f8d375_0\n",
      "  - openssl=1.1.1e=h516909a_0\n",
      "  - pandas=1.0.3=py37h0da4684_0\n",
      "  - parso=0.6.2=py_0\n",
      "  - pexpect=4.8.0=py37hc8dfbb8_1\n",
      "  - pickleshare=0.7.5=py37hc8dfbb8_1001\n",
      "  - pip=20.0.2=py_2\n",
      "  - prompt-toolkit=3.0.4=py_0\n",
      "  - ptyprocess=0.6.0=py_1001\n",
      "  - pygments=2.6.1=py_0\n",
      "  - python=3.7.6=h8356626_5_cpython\n",
      "  - python-dateutil=2.8.1=py_0\n",
      "  - python_abi=3.7=1_cp37m\n",
      "  - pytz=2019.3=py_0\n",
      "  - pyzmq=19.0.0=py37hac76be4_1\n",
      "  - readline=8.0=hf8c457e_0\n",
      "  - setuptools=46.1.1=py37hc8dfbb8_0\n",
      "  - six=1.14.0=py_1\n",
      "  - sqlite=3.30.1=hcee41ef_0\n",
      "  - tk=8.6.10=hed695b0_0\n",
      "  - tornado=6.0.4=py37h8f50634_1\n",
      "  - traitlets=4.3.3=py37hc8dfbb8_1\n",
      "  - wcwidth=0.1.8=py_0\n",
      "  - wheel=0.34.2=py_1\n",
      "  - xz=5.2.4=h516909a_1002\n",
      "  - zeromq=4.3.2=he1b5a44_2\n",
      "  - zlib=1.2.11=h516909a_1006\n",
      "prefix: /home/vitoz/miniconda3/envs/bbsnippets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda env export -p {sys.prefix}"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.3.4"
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:bbsnippets]",
   "language": "python",
   "name": "conda-env-bbsnippets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
